---
title: "NSE Stock prices"
author: "Reinp"
date: "`r Sys.Date()`"
output:
  html_document: 
    keep_md: yes
  word_document: default
  pdf_document: default
---

# R Programming

## Set Chunk requirements

```{r setup, include=TRUE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)

```

## loading Relevant packages and Data Set

```{r Import relevant packages}
#Import relevant packages

## tidyverse includes readr, ggplot2, dplyr, forcats, tibble, tidyr, purrr, stringr
library(tidyverse) 
library(readxl)
library(janitor)
library(lubridate)
library(scales)
library(plotly)
library(forecast)
library(mgcv)


## loading the csv data set
setwd('F:\\Documents\\Reinp\\GitHub Respositories\\Nairobi-Securities-Exchange-Trading-Summary')

NSE_Stock_prices_2016_2020 <- read_excel("data/NSE Stock prices 2017 - 2020.xlsx",
                              sheet = "NSE Stock data 2017 - 2020")


NSE_Stock_prices_2021_2025 <- read_excel("data/NSE Stock prices 2021 - 2025.xlsx",
                              sheet = "NSE Stock data 2021 - 2025")


NSE_unique <- read_excel("data/NSE Stock prices 2021 - 2025.xlsx",
                              sheet = "Unique")


#combine the data frames by rows


NSE_Stock_prices_raw <- rbind(NSE_Stock_prices_2016_2020, NSE_Stock_prices_2021_2025)


```


```{r}

NSE_Stock_prices <- merge(NSE_unique %>%
                                      select(-4, -7)
                     , NSE_Stock_prices_raw %>%
                        select(-4, -11, -12) ,
                     by.x = "CODE", 
                     by.y = "CODE") #InnerJoin

NSE_Stock_prices <- NSE_Stock_prices%>%
  janitor:: clean_names()%>%
  mutate(date = ymd(date))%>%
  arrange(date, sector, name)



View(NSE_Stock_prices)

```


## Structure of the Data

```{r Structure of the Data, results="hide"}

head(NSE_Stock_prices)

tail(NSE_Stock_prices)

# How many variables and observations are there?
ncol(NSE_Stock_prices)

nrow(NSE_Stock_prices)

#learn more about the dataset

class(NSE_Stock_prices)
typeof(NSE_Stock_prices) 
length(NSE_Stock_prices)

```

## Cleaning Data 

### Missing Values

```{r}
# check number of missing values in our data
sapply(NSE_Stock_prices,function(x) sum(is.na(x)))

```

### Columns

```{r}

NSE_Stock_prices <- NSE_Stock_prices%>% 
  mutate(volume_of_shares_traded = 
      ifelse( volume_of_shares_traded == "-" | is.na(volume_of_shares_traded),"0",
              volume_of_shares_traded))%>%
  mutate(volume_of_shares_traded = as.numeric(volume_of_shares_traded))

str(NSE_Stock_prices$volume_of_shares_traded)

```

### Adding Columns

```{r}

NSE_Stock_prices1 <- NSE_Stock_prices%>%
  mutate(turn_over = days_trading_vwap_price * volume_of_shares_traded)%>%
  mutate(change = days_trading_vwap_price - previous_days_vwap_price )%>%
  mutate(percentage_change = round((change/previous_days_vwap_price)*100,3) )%>%
  mutate(day_month = day(date))%>%
                       mutate(month_name = month(date, label = TRUE))%>%
                       mutate(year = factor(year(date), ordered = TRUE))%>%
                       mutate(day_year = factor(yday(date), ordered = TRUE))%>% #day of year
                       mutate(week_year = factor(week(date), ordered = TRUE))%>% #week of year
                       mutate(week_year_date = ceiling_date(date, unit = "week"))%>% 
                       mutate(month_year_date = floor_date(date, unit = "month"))

View(NSE_Stock_prices1)

names(NSE_Stock_prices1) #display variable names  
str(NSE_Stock_prices1)
```

## Visualizing Time series data

```{r}

total_traded_daily <- NSE_Stock_prices1%>%
 group_by(date, security_type_general)%>%
  summarise( total_volume_traded = sum(volume_of_shares_traded),
            total_turnover = sum(turn_over), .groups = 'drop')%>%
             drop_na()

total_traded_weekly <- NSE_Stock_prices1%>%
 group_by(week_year_date, security_type_general)%>%
  summarise( total_volume_traded = sum(volume_of_shares_traded),
            total_turnover = sum(turn_over), .groups = 'drop')%>%
             drop_na()

total_traded_monthly <- NSE_Stock_prices1%>%
 group_by(month_year_date, security_type_general)%>%
  summarise( total_volume_traded = sum(volume_of_shares_traded),
            total_turnover = sum(turn_over), .groups = 'drop')%>%
             drop_na()

total_traded_yearly <- NSE_Stock_prices1%>%
 group_by(year, security_type_general)%>%
  summarise( total_volume_traded = sum(volume_of_shares_traded),
            total_turnover = sum(turn_over), .groups = 'drop')%>%
             drop_na()

```


```{r}


ggplot(data=total_traded_daily%>%
         filter(security_type_general != "Index")%>%
         arrange( security_type_general, date)) +
  geom_line(aes(x=date, y=total_volume_traded, colour=security_type_general))+
  scale_x_date(date_labels = "%d-%b-%y", date_breaks = "60 days")+ 
  scale_y_continuous(labels = scales::comma, n.breaks = 10) +
  theme(axis.text.x = element_text(angle = 90, size = 8, face = "bold"),
        plot.title = element_text(hjust = 0.5),
        legend.position="bottom")+
  labs(title="Daily volume traded ", x="day_date", y ="Total volume")+
  guides(col = guide_legend(ncol = 2))


ggplot(data=total_traded_daily%>%
         filter(security_type_general != "Index")%>%
         arrange( security_type_general, date)) +
  geom_line(aes(x=date, y=total_turnover, colour=security_type_general))+
  scale_x_date(date_labels = "%d-%b-%y", date_breaks = "60 days") +
  scale_y_continuous(labels = scales::comma, n.breaks = 10) +
  theme(axis.text.x = element_text(angle = 90, size = 8, face = "bold"),
        plot.title = element_text(hjust = 0.5),
        legend.position="bottom")+
  labs(title="Daily turnover traded ", x="day_date", y ="Total turnover (KES)")+
  guides(col = guide_legend(ncol = 2))


ggplot(data=total_traded_weekly%>% 
         filter(security_type_general != "Index")%>%
         arrange( security_type_general, week_year_date)) +
  geom_line(aes(x=week_year_date, y=total_volume_traded, colour=security_type_general))+
  scale_x_date(date_labels = "%d-%b-%y", date_breaks = "8 weeks") +
  scale_y_continuous(labels = scales::comma, n.breaks = 12) +
  theme(axis.text.x = element_text(angle = 90, size = 8, face = "bold"),
        plot.title = element_text(hjust = 0.5),
        legend.position="bottom")+
  labs(title="Weekly volume traded ", x="week_date", y ="Total volume")+
  guides(col = guide_legend(ncol = 2))


ggplot(data=total_traded_weekly%>% 
         filter(security_type_general != "Index")%>%
         arrange( security_type_general, week_year_date)) +
  geom_line(aes(x=week_year_date, y=total_turnover, colour=security_type_general))+
  scale_x_date(date_labels = "%d-%b-%y", date_breaks = "8 weeks") +
  scale_y_continuous(labels = scales::comma, n.breaks = 12) +
  theme(axis.text.x = element_text(angle = 90, size = 8, face = "bold"),
        plot.title = element_text(hjust = 0.5),
        legend.position="bottom")+
  labs(title="Weekly turnover traded ", x="week_date", y ="Total turnover (KES)")+
  guides(col = guide_legend(ncol = 2))

```


```{r}
Safaricom <- NSE_Stock_prices1%>%
  select(date, name, days_trading_vwap_price, volume_of_shares_traded, year)%>%
  mutate(year = year(date))%>%
                       mutate(month_num = month(date, label = FALSE))%>%
  mutate(month_name = month(date, label = TRUE))%>%
  filter(name == "Safaricom Plc")%>%
  mutate(date_numeric = as.numeric(date))

ggplot(Safaricom, aes(x = date, y = days_trading_vwap_price)) +
	geom_line() +
	scale_x_date(date_labels = "%Y", date_breaks = "1 year") +
	theme_classic()
```


## Trend Lines

When you are conducting an exploratory analysis of time-series data, you'll need to identify trends while ignoring random fluctuations in your data.

### 1. Global smoothers

One of the simplest methods to identify trends is to fit a ordinary least squares regression model to the data. The model most people are familiar with is the linear model, but you can add other polynomial terms for extra flexibility. 

**Avoid polynomials of degrees larger than three because they are less stable.**

```{r}

ti = 1:length(Safaricom$days_trading_vwap_price)
m1 = lm(Safaricom$days_trading_vwap_price~ti)
m2 = lm(Safaricom$days_trading_vwap_price~ti+I(ti^2))
m3 = lm(Safaricom$days_trading_vwap_price~ti+I(ti^2)+I(ti^3))
 

    plot_ly(x=Safaricom$date, y=Safaricom$days_trading_vwap_price, type="scatter", mode="lines",
            line=list(color=rgb(0.8,0.8,0.8,0.8), width=4), name="VWAP- Safaricom")%>%
  add_lines( x=Safaricom$date, y=predict(m1), line=list(dash="solid", width = 1.5, color=NULL),
             name="Linear")%>%
  add_lines( x=Safaricom$date, y=predict(m2), line=list(dash="solid", width = 1.5, color=NULL),
             name="Quadratic")%>%
  add_lines( x=Safaricom$date, y=predict(m3), line=list(dash="solid", width = 1.5, color=NULL),
             name="Cubic")%>%
  layout(title = "Global smoothers")



```


### 2. Local Smoothers

#### Running line smoothers

The running line smoother reduces the bias by fitting a linear regression in a local neighborhood of the target value. A popular algorithm using the running line smoother is **Friedman’s super smoother supsmu**, which by default uses cross-validation to find the best span.

```{r}


rlcv = supsmu(Safaricom$date, Safaricom$days_trading_vwap_price)
rlst = supsmu(Safaricom$date, Safaricom$days_trading_vwap_price, span = 0.05)
rllt = supsmu(Safaricom$date, Safaricom$days_trading_vwap_price, span = 0.75)
 
     plot_ly(x=Safaricom$date, y=Safaricom$days_trading_vwap_price,
             type="scatter", mode="lines", line = list(color=rgb(0.8,0.8,0.8,0.8), width=4),
             name="VWAP- Safaricom")%>%
    add_lines(x=Safaricom$date,y=rllt$y, line=list(dash="solid", width = 1.5, color=NULL),
              name="Span = 0.75")%>%
    add_lines(x=Safaricom$date,y=rlst$y, line=list(dash="solid", width = 1.5, color=NULL),
              name="Span = 0.05")%>%
    add_lines(x=Safaricom$date,y=rlcv$y, line=list(dash="solid", width = 1.5, color=NULL),
              name="Cross-validated span")%>%
    layout(title = "Running line smoothers",
           legend = list(orientation = 'h',
                       xanchor = "center",  # use center of legend as anchor
                     x = 0.5# put legend in center of x-axis
                     ))

```

#### Kernel smoothers

An alternative approach to specifying a neighborhood is to decrease weights further away from the target value. These estimates are much smoother than the results from either the running mean (moving average) or running line smoothers.

```{r}

ks1 = ksmooth(Safaricom$date, Safaricom$days_trading_vwap_price, "normal", 60, x.points=Safaricom$date)
ks2 = ksmooth(Safaricom$date, Safaricom$days_trading_vwap_price, "normal", 30, x.points=Safaricom$date)
 
      plot_ly(x=Safaricom$date, y=Safaricom$days_trading_vwap_price, type="scatter", mode="lines",
              line=list(color=rgb(0.8,0.8,0.8,0.8), width=4),name="VWAP- Safaricom")%>%
      add_lines(x=ks1$x, y=ks1$y, line=list(dash="solid", width = 1.5, color=NULL),
                name="Bandwidth = 60")%>%
      add_lines(x=ks1$x, y=ks2$y, line=list(dash="solid", width = 1.5, color=NULL),
                name="Bandwidth = 30")%>%
      layout( title = "Kernel smoother")

```

#### Smoothing splines

Splines consist of a piece-wise polynomial with pieces defined by a sequence of knots where the pieces join smoothly. A smoothing splines is estimated by minimizing a criterion containing a penalty for both goodness of fit, and smoothness. The trade-off between the two is controlled by the smoothing parameter **lambda**, which is typically chosen by cross-validation.

In the base package, **smooth.spline** can be used to compute splines, but it is more common to use the **GAM function in mgcv**. Both functions use cross-validation to choose the default smoothing parameter; but the results vary between implementations. 

Another advantage to using GAM is that it allows estimation of confidence intervals.

```{r}

require(mgcv)
sp.base = smooth.spline(Safaricom$date, Safaricom$days_trading_vwap_price)

sp.cr = gam(Safaricom$days_trading_vwap_price~s(Safaricom$date_numeric, bs="cr"))
sp.gam = gam(Safaricom$days_trading_vwap_price~s(Safaricom$date_numeric))
sp.pred = predict(sp.gam, type="response", se.fit=TRUE)
sp.df = data.frame(x=sp.gam$model[,2], y=sp.pred$fit,
                    lb=as.numeric(sp.pred$fit - (1.96 * sp.pred$se.fit)),
                    ub=as.numeric(sp.pred$fit + (1.96 * sp.pred$se.fit)))
sp.df = sp.df[order(sp.df$x),]


    plot_ly(x=Safaricom$date, y=Safaricom$days_trading_vwap_price, type="scatter", mode="lines",
            line=list(color=rgb(0.8,0.8,0.8,0.8), width=4),name="VWAP- Safaricom")%>%
    add_lines(x=Safaricom$date, y=sp.df$y, name="GAM", line=list(color="#366092", width=2))%>%
    add_ribbons(x=as.Date(sp.df$x, origin="1970-01-01"), ymin=sp.df$lb, ymax=sp.df$ub,
                name="GAM 95% CI", line=list(color="#366092", opacity=0.4, width=0))%>%
    add_lines(x=Safaricom$date, y=predict(sp.base)$y, name="smooth.spline",
              line=list(color="orange", width=2))%>%
    layout(title="Smoothing splines")
    

```

#### Loess

LOESS (Locally Estimated Scatterplot Smoother) combines local regression with kernels by using locally weighted polynomial regression (by default, quadratic regression with tri-cubic weights).It also allows estimation of approximate confidence intervals. 

However, it is important to note that unlike **supsmu, smooth.spline or gam**, loess does not use cross-validation. By default, the span is set to 0.75; that is, the estimated smooth at each target value consists of a local regression constructed using 75% of the data points closest to the target value. This span is fairly large and results in estimated values that are smoother than those from other methods.

```{r}


ll.rough = loess(Safaricom$days_trading_vwap_price~ Safaricom$date_numeric, span=0.1)
ll.smooth = loess(Safaricom$days_trading_vwap_price~ Safaricom$date_numeric, span=0.75)
 
    plot_ly(x=Safaricom$date, y=Safaricom$days_trading_vwap_price,
               type="scatter", mode="lines", name="VWAP- Safaricom",
               line=list(color=rgb(0.8,0.8,0.8,0.8), width=4))%>%
       add_lines(x=Safaricom$date, y=predict(ll.smooth), name="Span = 0.75",
                 line =list(dash="solid", width = 1.5, color=NULL))%>%
       add_lines(x=Safaricom$date, y=fitted(ll.rough), name="Span = 0.10",
                 line =list(dash="solid", width = 1.5, color=NULL))%>%
      layout(title = "LOESS")


```

```{r}
ll.pred = predict(ll.smooth, se = TRUE)


ll.df = data.frame(x=as.Date(ll.smooth$x, origin="1970-01-01"), fit=ll.pred$fit,
lb = ll.pred$fit - (1.96 * ll.pred$se),
ub = ll.pred$fit + (1.96 * ll.pred$se))
ll.df = ll.df[order(ll.df$x),]

 
 
    plot_ly(x=Safaricom$date, y=Safaricom$days_trading_vwap_price,
                 type="scatter", mode="lines", name="VWAP- Safaricom",
            line = list(color=rgb(0.8,0.8,0.8,0.8), width=4))%>%
    add_lines(x=as.Date(Safaricom$date_numeric, origin="1970-01-01"),
              y=ll.df$fit, name="Mean", line=list(color="#366092", width=2))%>%
    add_ribbons(x=as.Date(Safaricom$date_numeric, origin="1970-01-01"),
                ymin=ll.df$lb, ymax=ll.df$ub, name="95% CI", line=list(opacity=0.4, width=0, color="#366092"))%>%
  layout(title = "LOESS with confidence intervals")

```

## Statistical analysis of time series data

### Decomposition

Time series data can contain multiple patterns acting at different temporal scales. The process of isolating each of these patterns is known as decomposition.

#### Smooth Pattern

We can see this pattern more clearly by plotting a loess regression through the data. A loess regression fits a smooth curve between two variables.

This is known as a **“smooth” pattern**, one that increases or decreases regularly (monotonically) over the course of the time series. 

***span*** sets the number of points used to plot each local regression in the curve: the smaller the number, the more points are used and the more closely the curve will fit the original data.


```{r}
Safaricom_weekly <- NSE_Stock_prices1%>%
  select(name, days_trading_vwap_price, year, week_year_date, week_year)%>%
  filter(name == "Safaricom Plc")%>%
  group_by(name, year, week_year_date, week_year)%>%
  summarise(days_trading_vwap_price = round(mean(days_trading_vwap_price), 2), .groups = 'drop')%>%
  mutate(week_year_numeric = as.numeric(week_year_date))

Safaricom_weekly$id_no <- 1:nrow(Safaricom_weekly)


```



```{r}

ggplot(Safaricom_weekly, aes(x = week_year_date, y = days_trading_vwap_price)) +
	geom_line() +
  geom_smooth(method = "loess", se = FALSE, span = 0.6) +
	scale_x_date(date_labels = "%Y", date_breaks = "1 year") +
	theme_classic()

```

#### Seasonal Pattern

Next, there can be some peaks and troughs that occur regularly in each year. This is a **“seasonal” pattern**. We can investigate this pattern more by plotting each year as it’s own line and comparing the different years:

```{r}

ggplot(Safaricom_weekly%>%
         mutate(week_year = as.numeric(week_year)),
       aes(x = week_year, y = days_trading_vwap_price, group = year)) +
	geom_line(aes(colour = year)) +
  scale_x_continuous(n.breaks = 26)+
	theme_classic()



```

#### Cyclic Pattern

**“Cyclic”** trends are similar to seasonal trends in that they recur over time, but occur over longer time scales. It may be that the general upward trend and plateau seen with the loess regression may be part of a longer decadal cycle related to sunspot activity, but this is impossible to test without a longer time series.

An alternative method to generating these plots in ggplot2 is to convert the time series data frame to a ts class object and decompose it using stl() from the stats package. This reduces the ability to customise the plots, but is arguably quicker:

```{r}

# Transform to `ts` class
Safaricom_ts <- ts(Safaricom_weekly$days_trading_vwap_price, start = min(Safaricom_weekly$week_year_date), end = max(Safaricom_weekly$week_year_date),
                 freq = 7)  
# Specify start and end, measurement frequency (monthly = 12, daily = 7, quartely = 4, weekly = 52 )


# Decompose using `stl()`
Safaricom_stl <- stl(Safaricom_ts, s.window = "period")

# Generate plots
plot(Safaricom_stl)  # top=original data, second=estimated seasonal, third=estimated smooth trend, bottom=estimated irregular element i.e. unaccounted for variation


monthplot(Safaricom_ts)  # variation for each month
seasonplot(Safaricom_ts)

```


## Forecasting

Often time series data are used to predict what might happen in the future, given the patterns seen in the data. This is known as **forecasting**. When we do prediction and forecasting we do not have information on the whole time series: we have observed up to time ***t*** and we want to forecast ahead of ***t+k***.

Standard statistical models assume indipendence of observations. In time series this assumption does not hold. What we want to model in time series is such dependence as the history untill time t and we have to predict what will happen at time t+k. We call such dependence **autocorrelation** meaning that each observation is related to itself at the previous time. If there is autocorrelation, we need to include the dependent variable suitably lagged as predictive variables in the model.

The most commonly used methods to forecast time series data are

- **ETS models:** ETS stands for Error, Trend, Seasonality. ETS models are also known as Exponential Smoothing State Space models. ETS models are used for modelling how a single variable will change over time by identifying its underlying trends, not taking into account any other variables. ETS models differ from a simple moving average by weighting the influence of previous points on future time points based on how much time is between the two points. i.e. over a longer period of time it is more likely that some unmeasured condition has changed, resulting in different behaviour of the variable that has been measured.


- **ARIMA models:** The ARIMA (auto-regressive integrated moving average) model makes forecasts based only on the historical values of the forecasting variable. The model assumes that the future values of a variable linearly depend on its past values, as well as on the values of past (stochastic) shocks.


- **ARIMAX models:** An Auto-regressive Integrated Moving Average with Explanatory Variable (ARIMAX) model can be viewed as a multiple regression model with one or more auto-regressive (AR) terms and/or one or more moving average (MA) terms. This method is suitable for forecasting when data is stationary/non stationary, and multivariate with any type of patterns in the data viz. level/trend /seasonality/cyclicity.


- **RNNs models:** It requires large amount of data and time for optimum learning and the results are not fully inferential in terms of confidence intervals.


- **XGBoost models:** Tends to give results which are smoothened thereby reducing error but it doesn’t capture peaks and troughs convincingly


### 1. ARIMA models

ARIMA models are the most general class of models for forecasting time series. They have three components:

 - AR: the autoregressive component which includes lags of the dependent variable as predictive variables in the model

 - I : the integration component which may be needed in order to obtain stationary (note that a series is stationary if it has the same statistical properties throughout time, i.e. same variance and mean)

 - MA: the moving average component that means that lags of the errors are included in the model


An ARIMA model can be considered as a special type of regression model in which the dependent variable has been stationarized (if necessary through the I-component) and the independent variables are all lags of the dependent variable (the AR-component) and/or lags of the errors (the MA-component).

In ARIMA model, there may be drifts that interpret a linear trend and/or exogenous variables that may help the prediction.

ARIMA models are useful when we work with observations that are correlated, i.e. when yt is correlated with yt−k.

```{r}
require(forecast)

par(mfrow = c(1,2))
acf(as.ts(Safaricom$days_trading_vwap_price), main = "")
pacf(as.ts(Safaricom$days_trading_vwap_price), main = "")
```

The forecast package in R contains a very useful function called auto.arima which helps us select the best ARIMA model. More specifically, it searches over all possible models within the order constraints provided and it returns the best ARIMA model according to AIC or BIC value.

```{r}

arima1 <- auto.arima(as.ts(Safaricom$days_trading_vwap_price)
                     )
arima1


```

In order to qualitatively assess the goodness of the above arima models, let us compare the predicted values with the observed ones:

```{r}
df1 <- tibble(observed = Safaricom$days_trading_vwap_price, predicted = as.numeric(arima1$fitted), time = Safaricom$date) %>% 
  mutate(abs_error = abs((observed - predicted)/observed*100))


ggplot(gather(df1 %>% select(-abs_error), obs_pred, value, -time)%>% 
         mutate(obs_pred = factor(obs_pred, levels = c("predicted", "observed"))), 
       aes(x = time, y = value, col = obs_pred)) +
  geom_line() +
  xlab("") + ylab("") + labs(title = "ARIMA Model - Goodness of Fit")+
   scale_color_manual(values=c("black", "hotpink")) +
 scale_x_date(date_labels = "%d-%b-%y", date_breaks = "60 days") +
  scale_y_continuous( n.breaks = 8) +
  theme_bw() + theme(legend.title = element_blank(),
                     axis.text.x  = element_text(angle=90, vjust=0.5, size = 8, face = "bold"))

```

```{r}

#So first we split the dataset, allowing for a varying index:

train_index <- round(nrow(Safaricom)*0.85)
n_total <- nrow(Safaricom)

```



```{r, message = FALSE, warning = FALSE}

Safaricom_train1 <- Safaricom[1:(train_index),]
Safaricom_test1 <- Safaricom[(train_index+1):n_total,]
predicted1 <- numeric(n_total-train_index)

#Then we apply a for cycle that iterates model and estimates one day ahead:

for (i in 1:(n_total-train_index)) {
  Safaricom_train_1 <- Safaricom[1:(train_index-1+i),]
  arima_model_1 <- auto.arima(as.ts(Safaricom_train_1$days_trading_vwap_price)
                     )
  pred_1 <- forecast(arima_model_1, 1)
  
  predicted1[i] <- pred_1[["mean"]]
  #predicted1[i] <- pred$upper
  #predicted1[i] <- pred$lower
  #predicted1[i] <- pred$fitted
}


df_pred_1 <- tibble(obs = c(Safaricom_train1$days_trading_vwap_price, Safaricom_test1$days_trading_vwap_price), 
                  predicted = c(Safaricom_train1$days_trading_vwap_price, predicted1), 
                  time = Safaricom$date)

```


```{r}
ggplot(gather(df_pred_1, obs_pred, value, -time) %>% 
         mutate(obs_pred = factor(obs_pred, levels = c( "predicted", "obs"))), 
       aes(x = time, y = value, col = obs_pred
           #,linetype = obs_pred
           )) +
  geom_line() +
  xlab("") + ylab("") + labs(title = "ARIMA Forecasting")+
  scale_color_manual(values=c( "black", "hotpink")) +
  #scale_linetype_manual(values=c(2, 1)) +
  scale_x_date(date_labels = "%d-%b-%y", date_breaks = "60 days") +
  scale_y_continuous( n.breaks = 8) +
  theme_bw() + theme(legend.title = element_blank(),
                     axis.text.x  = element_text(angle=90, vjust=0.5, size = 8, face = "bold"))


```


### ARIMAX

ARIMAX is related to the ARIMA technique but, while ARIMA is suitable for datasets that are univariate. ARIMAX is suitable for analysis where there are additional exogenous variables usually in numeric format.

Saying that there is no autoregressive componenent means that given X, yt does no more depend on yt−k.

```{r}

arima2 <- auto.arima(as.ts(Safaricom$days_trading_vwap_price)
                     ,xreg = cbind(Safaricom$year,
                                   Safaricom$month_num
                                   )
                     )
arima2

```


```{r}

df2 <- tibble(observed = Safaricom$days_trading_vwap_price, predicted = as.numeric(arima2$fitted), time = Safaricom$date) %>% 
  mutate(abs_error = abs((observed - predicted)/observed*100))


ggplot(gather(df2 %>% select(-abs_error), obs_pred, value, -time)%>% 
         mutate(obs_pred = factor(obs_pred, levels = c("predicted", "observed"))), 
       aes(x = time, y = value, col = obs_pred)) +
  geom_line() +
  xlab("") + ylab("") + labs(title = "ARIMAX Model - Goodness of Fit")+
   scale_color_manual(values=c("black", "hotpink")) +
 scale_x_date(date_labels = "%d-%b-%y", date_breaks = "60 days") +
  scale_y_continuous( n.breaks = 8) +
  theme_bw() + theme(legend.title = element_blank(),
                     axis.text.x  = element_text(angle=90, vjust=0.5, size = 8, face = "bold"))


```


```{r, message = FALSE, warning = FALSE}
#So first we split the dataset, allowing for a varying index:


Safaricom_train2 <- Safaricom[1:(train_index),]
Safaricom_test2 <- Safaricom[(train_index+1):n_total,]
predicted2 <- numeric(n_total-train_index)

#Then we apply a for cycle that iterates model and estimates one day ahead:

for (i in 1:(n_total-train_index)) {
  Safaricom_train_2 <- Safaricom[1:(train_index-1+i),]
  arima_model_2 <- auto.arima(as.ts(Safaricom_train_2$days_trading_vwap_price),
                              xreg = cbind(Safaricom_train_2$year,
                                   Safaricom_train_2$month_num
                                   )
                     )
  pred_2 <- forecast(arima_model_2, 1,
                              xreg = cbind(Safaricom_test2$year[i],
                                   Safaricom_test2$month_num[i]
                                   )
                   )
  
  predicted2[i] <- pred_2[["mean"]]
  #predicted[i] <- pred$upper
  #predicted[i] <- pred$lower
  #predicted[i] <- pred$fitted
}


df_pred_2 <- tibble(obs = c(Safaricom_train2$days_trading_vwap_price, Safaricom_test2$days_trading_vwap_price), 
                  predicted = c(Safaricom_train2$days_trading_vwap_price, predicted2), 
                  time = Safaricom$date)

```

```{r}
ggplot(gather(df_pred_2, obs_pred, value, -time) %>% 
         mutate(obs_pred = factor(obs_pred, levels = c( "predicted", "obs"))), 
       aes(x = time, y = value, col = obs_pred
           #,linetype = obs_pred
           )) +
  geom_line() +
  xlab("") + ylab("") + labs(title = "ARIMAX Forecasting")+
  scale_color_manual(values=c( "black", "hotpink")) +
  #scale_linetype_manual(values=c(2, 1)) +
  scale_x_date(date_labels = "%d-%b-%y", date_breaks = "60 days") +
  scale_y_continuous( n.breaks = 8) +
  theme_bw() + theme(legend.title = element_blank(),
                     axis.text.x  = element_text(angle=90, vjust=0.5, size = 8, face = "bold"))


```








